# Sciluigi needs to know how to run your containers
# This configuration file helps specify the options needed
[DEFAULT]
# Which container engine to use. Options include:
#  docker -> docker on the hosting machine
#  aws_batch -> AWS batch
#  pbs -> PBS / torque via qsub
#  slurm -> slurm HPC management engine, via srun
engine = docker

# How many vcpu to request (concurrent threads)
vcpu = 1 

# Maximum memory, in MB
mem = 4096

# Time limit in minutes
timeout = 10080

container_working_dir = /tmp/

# Some engine specific options
# **    singularity (for slurm and pbs)     **
# where should we store our singularity containers. 
# Should be some shared filesystem between nodes
container_cache = 

# **    slurm   **
# To which partition should we submit
slurm_partition = 

# **    PBS     **
# Under which account should jobs be submitted
pbs_account = 
# to which queue?
pbs_queue = 
# Path on shared filesystem between nodes
# To use to store scripts. 
pbs_scriptpath = 


# **  AWS batch  **
# The role ID needed for tasks to access S3
aws_jobRoleArn = 
# S3 bucket to use for temporary upload / download of files
aws_s3_scratch_loc = 
# Which batch job queue should jobs be submitted
aws_batch_job_queue = 
# Prefix to add to jobs (human readable)
aws_batch_job_prefix = 
# How often should we poll batch (secs)
aws_batch_job_poll_sec = 10
# Where can we find credentials (defaults to ~/.aws if not specified)
aws_secrets_loc = 
# How many times to try submitting via boto before being killed
aws_boto_max_tries = 10

# Now specify some defaults for tasks with specific resource need types
# Overriding only the relevant options

# High memory relative to number of CPU
[highmem]
mem = 120000
vcpu = 1

# Mixed needs for moderate mulitthreaded tasks
[midcpu]
mem = 4096
vcpu = 4

# Big cpu and memory
[heavy]
mem = 120000
;vcpu = 12

# Minimal CPU and memory needs (suitable for IO limited tasks)
[light]
vcpu = 1
mem = 1024
